

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Index &mdash; nerva_torch  documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=5929fcd5"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="#" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            nerva_torch
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="_autosummary/nerva_torch.html">nerva_torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="_autosummary/nerva_torch.activation_functions.html">nerva_torch.activation_functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="_autosummary/nerva_torch.datasets.html">nerva_torch.datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="_autosummary/nerva_torch.layers.html">nerva_torch.layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="_autosummary/nerva_torch.learning_rate.html">nerva_torch.learning_rate</a></li>
<li class="toctree-l1"><a class="reference internal" href="_autosummary/nerva_torch.loss_functions.html">nerva_torch.loss_functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="_autosummary/nerva_torch.loss_functions_torch.html">nerva_torch.loss_functions_torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="_autosummary/nerva_torch.matrix_operations.html">nerva_torch.matrix_operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="_autosummary/nerva_torch.multilayer_perceptron.html">nerva_torch.multilayer_perceptron</a></li>
<li class="toctree-l1"><a class="reference internal" href="_autosummary/nerva_torch.optimizers.html">nerva_torch.optimizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="_autosummary/nerva_torch.softmax_functions.html">nerva_torch.softmax_functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="_autosummary/nerva_torch.training.html">nerva_torch.training</a></li>
<li class="toctree-l1"><a class="reference internal" href="_autosummary/nerva_torch.utilities.html">nerva_torch.utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="_autosummary/nerva_torch.weight_initializers.html">nerva_torch.weight_initializers</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">nerva_torch</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Index</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             

<h1 id="index">Index</h1>

<div class="genindex-jumpbox">
 <a href="#A"><strong>A</strong></a>
 | <a href="#B"><strong>B</strong></a>
 | <a href="#C"><strong>C</strong></a>
 | <a href="#D"><strong>D</strong></a>
 | <a href="#E"><strong>E</strong></a>
 | <a href="#F"><strong>F</strong></a>
 | <a href="#G"><strong>G</strong></a>
 | <a href="#H"><strong>H</strong></a>
 | <a href="#I"><strong>I</strong></a>
 | <a href="#J"><strong>J</strong></a>
 | <a href="#L"><strong>L</strong></a>
 | <a href="#M"><strong>M</strong></a>
 | <a href="#N"><strong>N</strong></a>
 | <a href="#O"><strong>O</strong></a>
 | <a href="#P"><strong>P</strong></a>
 | <a href="#R"><strong>R</strong></a>
 | <a href="#S"><strong>S</strong></a>
 | <a href="#T"><strong>T</strong></a>
 | <a href="#U"><strong>U</strong></a>
 | <a href="#V"><strong>V</strong></a>
 | <a href="#Z"><strong>Z</strong></a>
 
</div>
<h2 id="A">A</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.activation_functions.html#nerva_torch.activation_functions.ActivationFunction">ActivationFunction (class in nerva_torch.activation_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.layers.html#nerva_torch.layers.ActivationLayer">ActivationLayer (class in nerva_torch.layers)</a>
</li>
      <li><a href="_autosummary/nerva_torch.activation_functions.html#nerva_torch.activation_functions.All_relu">All_relu() (in module nerva_torch.activation_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.activation_functions.html#nerva_torch.activation_functions.All_relu_gradient">All_relu_gradient() (in module nerva_torch.activation_functions)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.activation_functions.html#nerva_torch.activation_functions.AllReLUActivation">AllReLUActivation (class in nerva_torch.activation_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.matrix_operations.html#nerva_torch.matrix_operations.apply">apply() (in module nerva_torch.matrix_operations)</a>
</li>
      <li><a href="_autosummary/nerva_torch.utilities.html#nerva_torch.utilities.FunctionCall.as_scalar">as_scalar() (nerva_torch.utilities.FunctionCall method)</a>
</li>
      <li><a href="_autosummary/nerva_torch.utilities.html#nerva_torch.utilities.FunctionCall.as_string">as_string() (nerva_torch.utilities.FunctionCall method)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="B">B</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.layers.html#nerva_torch.layers.ActivationLayer.backpropagate">backpropagate() (nerva_torch.layers.ActivationLayer method)</a>

      <ul>
        <li><a href="_autosummary/nerva_torch.layers.html#nerva_torch.layers.BatchNormalizationLayer.backpropagate">(nerva_torch.layers.BatchNormalizationLayer method)</a>
</li>
        <li><a href="_autosummary/nerva_torch.layers.html#nerva_torch.layers.Layer.backpropagate">(nerva_torch.layers.Layer method)</a>
</li>
        <li><a href="_autosummary/nerva_torch.layers.html#nerva_torch.layers.LinearLayer.backpropagate">(nerva_torch.layers.LinearLayer method)</a>
</li>
        <li><a href="_autosummary/nerva_torch.layers.html#nerva_torch.layers.LogSoftmaxLayer.backpropagate">(nerva_torch.layers.LogSoftmaxLayer method)</a>
</li>
        <li><a href="_autosummary/nerva_torch.layers.html#nerva_torch.layers.SoftmaxLayer.backpropagate">(nerva_torch.layers.SoftmaxLayer method)</a>
</li>
        <li><a href="_autosummary/nerva_torch.layers.html#nerva_torch.layers.SReLULayer.backpropagate">(nerva_torch.layers.SReLULayer method)</a>
</li>
        <li><a href="_autosummary/nerva_torch.multilayer_perceptron.html#nerva_torch.multilayer_perceptron.MultilayerPerceptron.backpropagate">(nerva_torch.multilayer_perceptron.MultilayerPerceptron method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.layers.html#nerva_torch.layers.BatchNormalizationLayer">BatchNormalizationLayer (class in nerva_torch.layers)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="C">C</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.matrix_operations.html#nerva_torch.matrix_operations.column_repeat">column_repeat() (in module nerva_torch.matrix_operations)</a>
</li>
      <li><a href="_autosummary/nerva_torch.matrix_operations.html#nerva_torch.matrix_operations.columns_max">columns_max() (in module nerva_torch.matrix_operations)</a>
</li>
      <li><a href="_autosummary/nerva_torch.matrix_operations.html#nerva_torch.matrix_operations.columns_mean">columns_mean() (in module nerva_torch.matrix_operations)</a>
</li>
      <li><a href="_autosummary/nerva_torch.matrix_operations.html#nerva_torch.matrix_operations.columns_sum">columns_sum() (in module nerva_torch.matrix_operations)</a>
</li>
      <li><a href="_autosummary/nerva_torch.optimizers.html#nerva_torch.optimizers.CompositeOptimizer">CompositeOptimizer (class in nerva_torch.optimizers)</a>
</li>
      <li><a href="_autosummary/nerva_torch.training.html#nerva_torch.training.compute_accuracy">compute_accuracy() (in module nerva_torch.training)</a>
</li>
      <li><a href="_autosummary/nerva_torch.training.html#nerva_torch.training.compute_loss">compute_loss() (in module nerva_torch.training)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.training.html#nerva_torch.training.compute_statistics">compute_statistics() (in module nerva_torch.training)</a>
</li>
      <li><a href="_autosummary/nerva_torch.learning_rate.html#nerva_torch.learning_rate.ConstantScheduler">ConstantScheduler (class in nerva_torch.learning_rate)</a>
</li>
      <li><a href="_autosummary/nerva_torch.datasets.html#nerva_torch.datasets.create_npz_dataloaders">create_npz_dataloaders() (in module nerva_torch.datasets)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.Cross_entropy_loss">Cross_entropy_loss() (in module nerva_torch.loss_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.cross_entropy_loss">cross_entropy_loss() (in module nerva_torch.loss_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.Cross_entropy_loss_gradient">Cross_entropy_loss_gradient() (in module nerva_torch.loss_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.cross_entropy_loss_gradient">cross_entropy_loss_gradient() (in module nerva_torch.loss_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.CrossEntropyLossFunction">CrossEntropyLossFunction (class in nerva_torch.loss_functions)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="D">D</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.training.html#nerva_torch.training.SGDOptions.debug">debug (nerva_torch.training.SGDOptions attribute)</a>
</li>
      <li><a href="_autosummary/nerva_torch.matrix_operations.html#nerva_torch.matrix_operations.Diag">Diag() (in module nerva_torch.matrix_operations)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.matrix_operations.html#nerva_torch.matrix_operations.diag">diag() (in module nerva_torch.matrix_operations)</a>
</li>
      <li><a href="_autosummary/nerva_torch.matrix_operations.html#nerva_torch.matrix_operations.dot">dot() (in module nerva_torch.matrix_operations)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="E">E</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.matrix_operations.html#nerva_torch.matrix_operations.elements_sum">elements_sum() (in module nerva_torch.matrix_operations)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.matrix_operations.html#nerva_torch.matrix_operations.exp">exp() (in module nerva_torch.matrix_operations)</a>
</li>
      <li><a href="_autosummary/nerva_torch.learning_rate.html#nerva_torch.learning_rate.ExponentialScheduler">ExponentialScheduler (class in nerva_torch.learning_rate)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="F">F</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.layers.html#nerva_torch.layers.ActivationLayer.feedforward">feedforward() (nerva_torch.layers.ActivationLayer method)</a>

      <ul>
        <li><a href="_autosummary/nerva_torch.layers.html#nerva_torch.layers.BatchNormalizationLayer.feedforward">(nerva_torch.layers.BatchNormalizationLayer method)</a>
</li>
        <li><a href="_autosummary/nerva_torch.layers.html#nerva_torch.layers.Layer.feedforward">(nerva_torch.layers.Layer method)</a>
</li>
        <li><a href="_autosummary/nerva_torch.layers.html#nerva_torch.layers.LinearLayer.feedforward">(nerva_torch.layers.LinearLayer method)</a>
</li>
        <li><a href="_autosummary/nerva_torch.layers.html#nerva_torch.layers.LogSoftmaxLayer.feedforward">(nerva_torch.layers.LogSoftmaxLayer method)</a>
</li>
        <li><a href="_autosummary/nerva_torch.layers.html#nerva_torch.layers.SoftmaxLayer.feedforward">(nerva_torch.layers.SoftmaxLayer method)</a>
</li>
        <li><a href="_autosummary/nerva_torch.multilayer_perceptron.html#nerva_torch.multilayer_perceptron.MultilayerPerceptron.feedforward">(nerva_torch.multilayer_perceptron.MultilayerPerceptron method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.datasets.html#nerva_torch.datasets.from_one_hot">from_one_hot() (in module nerva_torch.datasets)</a>
</li>
      <li><a href="_autosummary/nerva_torch.utilities.html#nerva_torch.utilities.FunctionCall">FunctionCall (class in nerva_torch.utilities)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="G">G</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.utilities.html#nerva_torch.utilities.FunctionCall.get_value">get_value() (nerva_torch.utilities.FunctionCall method)</a>
</li>
      <li><a href="_autosummary/nerva_torch.activation_functions.html#nerva_torch.activation_functions.ActivationFunction.gradient">gradient() (nerva_torch.activation_functions.ActivationFunction method)</a>

      <ul>
        <li><a href="_autosummary/nerva_torch.activation_functions.html#nerva_torch.activation_functions.AllReLUActivation.gradient">(nerva_torch.activation_functions.AllReLUActivation method)</a>
</li>
        <li><a href="_autosummary/nerva_torch.activation_functions.html#nerva_torch.activation_functions.HyperbolicTangentActivation.gradient">(nerva_torch.activation_functions.HyperbolicTangentActivation method)</a>
</li>
        <li><a href="_autosummary/nerva_torch.activation_functions.html#nerva_torch.activation_functions.LeakyReLUActivation.gradient">(nerva_torch.activation_functions.LeakyReLUActivation method)</a>
</li>
        <li><a href="_autosummary/nerva_torch.activation_functions.html#nerva_torch.activation_functions.ReLUActivation.gradient">(nerva_torch.activation_functions.ReLUActivation method)</a>
</li>
        <li><a href="_autosummary/nerva_torch.activation_functions.html#nerva_torch.activation_functions.SigmoidActivation.gradient">(nerva_torch.activation_functions.SigmoidActivation method)</a>
</li>
        <li><a href="_autosummary/nerva_torch.activation_functions.html#nerva_torch.activation_functions.SReLUActivation.gradient">(nerva_torch.activation_functions.SReLUActivation method)</a>
</li>
        <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.CrossEntropyLossFunction.gradient">(nerva_torch.loss_functions.CrossEntropyLossFunction method)</a>
</li>
        <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.LogisticCrossEntropyLossFunction.gradient">(nerva_torch.loss_functions.LogisticCrossEntropyLossFunction method)</a>
</li>
        <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.LossFunction.gradient">(nerva_torch.loss_functions.LossFunction method)</a>
</li>
        <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.NegativeLogLikelihoodLossFunction.gradient">(nerva_torch.loss_functions.NegativeLogLikelihoodLossFunction method)</a>
</li>
        <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.SoftmaxCrossEntropyLossFunction.gradient">(nerva_torch.loss_functions.SoftmaxCrossEntropyLossFunction method)</a>
</li>
        <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.SquaredErrorLossFunction.gradient">(nerva_torch.loss_functions.SquaredErrorLossFunction method)</a>
</li>
        <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.StableSoftmaxCrossEntropyLossFunction.gradient">(nerva_torch.loss_functions.StableSoftmaxCrossEntropyLossFunction method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.optimizers.html#nerva_torch.optimizers.GradientDescentOptimizer">GradientDescentOptimizer (class in nerva_torch.optimizers)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="H">H</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.matrix_operations.html#nerva_torch.matrix_operations.hadamard">hadamard() (in module nerva_torch.matrix_operations)</a>
</li>
      <li><a href="_autosummary/nerva_torch.utilities.html#nerva_torch.utilities.FunctionCall.has_key">has_key() (nerva_torch.utilities.FunctionCall method)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.activation_functions.html#nerva_torch.activation_functions.Hyperbolic_tangent">Hyperbolic_tangent() (in module nerva_torch.activation_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.activation_functions.html#nerva_torch.activation_functions.Hyperbolic_tangent_gradient">Hyperbolic_tangent_gradient() (in module nerva_torch.activation_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.activation_functions.html#nerva_torch.activation_functions.HyperbolicTangentActivation">HyperbolicTangentActivation (class in nerva_torch.activation_functions)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="I">I</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.matrix_operations.html#nerva_torch.matrix_operations.identity">identity() (in module nerva_torch.matrix_operations)</a>
</li>
      <li><a href="_autosummary/nerva_torch.datasets.html#nerva_torch.datasets.infer_num_classes">infer_num_classes() (in module nerva_torch.datasets)</a>
</li>
      <li><a href="_autosummary/nerva_torch.multilayer_perceptron.html#nerva_torch.multilayer_perceptron.MultilayerPerceptron.info">info() (nerva_torch.multilayer_perceptron.MultilayerPerceptron method)</a>
</li>
      <li><a href="_autosummary/nerva_torch.layers.html#nerva_torch.layers.BatchNormalizationLayer.input_size">input_size() (nerva_torch.layers.BatchNormalizationLayer method)</a>

      <ul>
        <li><a href="_autosummary/nerva_torch.layers.html#nerva_torch.layers.LinearLayer.input_size">(nerva_torch.layers.LinearLayer method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.matrix_operations.html#nerva_torch.matrix_operations.inv_sqrt">inv_sqrt() (in module nerva_torch.matrix_operations)</a>
</li>
      <li><a href="_autosummary/nerva_torch.matrix_operations.html#nerva_torch.matrix_operations.is_column_vector">is_column_vector() (in module nerva_torch.matrix_operations)</a>
</li>
      <li><a href="_autosummary/nerva_torch.matrix_operations.html#nerva_torch.matrix_operations.is_row_vector">is_row_vector() (in module nerva_torch.matrix_operations)</a>
</li>
      <li><a href="_autosummary/nerva_torch.matrix_operations.html#nerva_torch.matrix_operations.is_square">is_square() (in module nerva_torch.matrix_operations)</a>
</li>
      <li><a href="_autosummary/nerva_torch.matrix_operations.html#nerva_torch.matrix_operations.is_vector">is_vector() (in module nerva_torch.matrix_operations)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="J">J</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.softmax_functions.html#nerva_torch.softmax_functions.LogSoftmaxFunction.jacobian">jacobian() (nerva_torch.softmax_functions.LogSoftmaxFunction method)</a>

      <ul>
        <li><a href="_autosummary/nerva_torch.softmax_functions.html#nerva_torch.softmax_functions.SoftmaxFunction.jacobian">(nerva_torch.softmax_functions.SoftmaxFunction method)</a>
</li>
        <li><a href="_autosummary/nerva_torch.softmax_functions.html#nerva_torch.softmax_functions.StableLogSoftmaxFunction.jacobian">(nerva_torch.softmax_functions.StableLogSoftmaxFunction method)</a>
</li>
        <li><a href="_autosummary/nerva_torch.softmax_functions.html#nerva_torch.softmax_functions.StableSoftmaxFunction.jacobian">(nerva_torch.softmax_functions.StableSoftmaxFunction method)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="L">L</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.layers.html#nerva_torch.layers.Layer">Layer (class in nerva_torch.layers)</a>
</li>
      <li><a href="_autosummary/nerva_torch.activation_functions.html#nerva_torch.activation_functions.Leaky_relu">Leaky_relu() (in module nerva_torch.activation_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.activation_functions.html#nerva_torch.activation_functions.Leaky_relu_gradient">Leaky_relu_gradient() (in module nerva_torch.activation_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.activation_functions.html#nerva_torch.activation_functions.LeakyReLUActivation">LeakyReLUActivation (class in nerva_torch.activation_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.learning_rate.html#nerva_torch.learning_rate.LearningRateScheduler">LearningRateScheduler (class in nerva_torch.learning_rate)</a>
</li>
      <li><a href="_autosummary/nerva_torch.layers.html#nerva_torch.layers.LinearLayer">LinearLayer (class in nerva_torch.layers)</a>
</li>
      <li><a href="_autosummary/nerva_torch.utilities.html#nerva_torch.utilities.load_dict_from_npz">load_dict_from_npz() (in module nerva_torch.utilities)</a>
</li>
      <li><a href="_autosummary/nerva_torch.multilayer_perceptron.html#nerva_torch.multilayer_perceptron.MultilayerPerceptron.load_weights_and_bias">load_weights_and_bias() (nerva_torch.multilayer_perceptron.MultilayerPerceptron method)</a>
</li>
      <li><a href="_autosummary/nerva_torch.matrix_operations.html#nerva_torch.matrix_operations.log">log() (in module nerva_torch.matrix_operations)</a>
</li>
      <li><a href="_autosummary/nerva_torch.matrix_operations.html#nerva_torch.matrix_operations.log_sigmoid">log_sigmoid() (in module nerva_torch.matrix_operations)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.softmax_functions.html#nerva_torch.softmax_functions.log_softmax">log_softmax() (in module nerva_torch.softmax_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.softmax_functions.html#nerva_torch.softmax_functions.log_softmax_jacobian">log_softmax_jacobian() (in module nerva_torch.softmax_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.Logistic_cross_entropy_loss">Logistic_cross_entropy_loss() (in module nerva_torch.loss_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.logistic_cross_entropy_loss">logistic_cross_entropy_loss() (in module nerva_torch.loss_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.Logistic_cross_entropy_loss_gradient">Logistic_cross_entropy_loss_gradient() (in module nerva_torch.loss_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.logistic_cross_entropy_loss_gradient">logistic_cross_entropy_loss_gradient() (in module nerva_torch.loss_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.LogisticCrossEntropyLossFunction">LogisticCrossEntropyLossFunction (class in nerva_torch.loss_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.softmax_functions.html#nerva_torch.softmax_functions.LogSoftmaxFunction">LogSoftmaxFunction (class in nerva_torch.softmax_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.layers.html#nerva_torch.layers.LogSoftmaxLayer">LogSoftmaxLayer (class in nerva_torch.layers)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.LossFunction">LossFunction (class in nerva_torch.loss_functions)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="M">M</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.datasets.html#nerva_torch.datasets.max_">max_() (in module nerva_torch.datasets)</a>
</li>
      <li><a href="_autosummary/nerva_torch.datasets.html#nerva_torch.datasets.MemoryDataLoader">MemoryDataLoader (class in nerva_torch.datasets)</a>
</li>
      <li>
    module

      <ul>
        <li><a href="_autosummary/nerva_torch.html#module-nerva_torch">nerva_torch</a>
</li>
        <li><a href="_autosummary/nerva_torch.activation_functions.html#module-nerva_torch.activation_functions">nerva_torch.activation_functions</a>
</li>
        <li><a href="_autosummary/nerva_torch.datasets.html#module-nerva_torch.datasets">nerva_torch.datasets</a>
</li>
        <li><a href="_autosummary/nerva_torch.layers.html#module-nerva_torch.layers">nerva_torch.layers</a>
</li>
        <li><a href="_autosummary/nerva_torch.learning_rate.html#module-nerva_torch.learning_rate">nerva_torch.learning_rate</a>
</li>
        <li><a href="_autosummary/nerva_torch.loss_functions.html#module-nerva_torch.loss_functions">nerva_torch.loss_functions</a>
</li>
        <li><a href="_autosummary/nerva_torch.loss_functions_torch.html#module-nerva_torch.loss_functions_torch">nerva_torch.loss_functions_torch</a>
</li>
        <li><a href="_autosummary/nerva_torch.matrix_operations.html#module-nerva_torch.matrix_operations">nerva_torch.matrix_operations</a>
</li>
        <li><a href="_autosummary/nerva_torch.multilayer_perceptron.html#module-nerva_torch.multilayer_perceptron">nerva_torch.multilayer_perceptron</a>
</li>
        <li><a href="_autosummary/nerva_torch.optimizers.html#module-nerva_torch.optimizers">nerva_torch.optimizers</a>
</li>
        <li><a href="_autosummary/nerva_torch.softmax_functions.html#module-nerva_torch.softmax_functions">nerva_torch.softmax_functions</a>
</li>
        <li><a href="_autosummary/nerva_torch.training.html#module-nerva_torch.training">nerva_torch.training</a>
</li>
        <li><a href="_autosummary/nerva_torch.utilities.html#module-nerva_torch.utilities">nerva_torch.utilities</a>
</li>
        <li><a href="_autosummary/nerva_torch.weight_initializers.html#module-nerva_torch.weight_initializers">nerva_torch.weight_initializers</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.optimizers.html#nerva_torch.optimizers.MomentumOptimizer">MomentumOptimizer (class in nerva_torch.optimizers)</a>
</li>
      <li><a href="_autosummary/nerva_torch.multilayer_perceptron.html#nerva_torch.multilayer_perceptron.MultilayerPerceptron">MultilayerPerceptron (class in nerva_torch.multilayer_perceptron)</a>
</li>
      <li><a href="_autosummary/nerva_torch.learning_rate.html#nerva_torch.learning_rate.MultiStepLRScheduler">MultiStepLRScheduler (class in nerva_torch.learning_rate)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="N">N</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.loss_functions_torch.html#nerva_torch.loss_functions_torch.negative_likelihood_loss_torch">negative_likelihood_loss_torch() (in module nerva_torch.loss_functions_torch)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.Negative_log_likelihood_loss">Negative_log_likelihood_loss() (in module nerva_torch.loss_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.negative_log_likelihood_loss">negative_log_likelihood_loss() (in module nerva_torch.loss_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.Negative_log_likelihood_loss_gradient">Negative_log_likelihood_loss_gradient() (in module nerva_torch.loss_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.negative_log_likelihood_loss_gradient">negative_log_likelihood_loss_gradient() (in module nerva_torch.loss_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.NegativeLogLikelihoodLossFunction">NegativeLogLikelihoodLossFunction (class in nerva_torch.loss_functions)</a>
</li>
      <li>
    nerva_torch

      <ul>
        <li><a href="_autosummary/nerva_torch.html#module-nerva_torch">module</a>
</li>
      </ul></li>
      <li>
    nerva_torch.activation_functions

      <ul>
        <li><a href="_autosummary/nerva_torch.activation_functions.html#module-nerva_torch.activation_functions">module</a>
</li>
      </ul></li>
      <li>
    nerva_torch.datasets

      <ul>
        <li><a href="_autosummary/nerva_torch.datasets.html#module-nerva_torch.datasets">module</a>
</li>
      </ul></li>
      <li>
    nerva_torch.layers

      <ul>
        <li><a href="_autosummary/nerva_torch.layers.html#module-nerva_torch.layers">module</a>
</li>
      </ul></li>
      <li>
    nerva_torch.learning_rate

      <ul>
        <li><a href="_autosummary/nerva_torch.learning_rate.html#module-nerva_torch.learning_rate">module</a>
</li>
      </ul></li>
      <li>
    nerva_torch.loss_functions

      <ul>
        <li><a href="_autosummary/nerva_torch.loss_functions.html#module-nerva_torch.loss_functions">module</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li>
    nerva_torch.loss_functions_torch

      <ul>
        <li><a href="_autosummary/nerva_torch.loss_functions_torch.html#module-nerva_torch.loss_functions_torch">module</a>
</li>
      </ul></li>
      <li>
    nerva_torch.matrix_operations

      <ul>
        <li><a href="_autosummary/nerva_torch.matrix_operations.html#module-nerva_torch.matrix_operations">module</a>
</li>
      </ul></li>
      <li>
    nerva_torch.multilayer_perceptron

      <ul>
        <li><a href="_autosummary/nerva_torch.multilayer_perceptron.html#module-nerva_torch.multilayer_perceptron">module</a>
</li>
      </ul></li>
      <li>
    nerva_torch.optimizers

      <ul>
        <li><a href="_autosummary/nerva_torch.optimizers.html#module-nerva_torch.optimizers">module</a>
</li>
      </ul></li>
      <li>
    nerva_torch.softmax_functions

      <ul>
        <li><a href="_autosummary/nerva_torch.softmax_functions.html#module-nerva_torch.softmax_functions">module</a>
</li>
      </ul></li>
      <li>
    nerva_torch.training

      <ul>
        <li><a href="_autosummary/nerva_torch.training.html#module-nerva_torch.training">module</a>
</li>
      </ul></li>
      <li>
    nerva_torch.utilities

      <ul>
        <li><a href="_autosummary/nerva_torch.utilities.html#module-nerva_torch.utilities">module</a>
</li>
      </ul></li>
      <li>
    nerva_torch.weight_initializers

      <ul>
        <li><a href="_autosummary/nerva_torch.weight_initializers.html#module-nerva_torch.weight_initializers">module</a>
</li>
      </ul></li>
      <li><a href="_autosummary/nerva_torch.optimizers.html#nerva_torch.optimizers.NesterovOptimizer">NesterovOptimizer (class in nerva_torch.optimizers)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="O">O</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.matrix_operations.html#nerva_torch.matrix_operations.ones">ones() (in module nerva_torch.matrix_operations)</a>
</li>
      <li><a href="_autosummary/nerva_torch.layers.html#nerva_torch.layers.Layer.optimize">optimize() (nerva_torch.layers.Layer method)</a>

      <ul>
        <li><a href="_autosummary/nerva_torch.multilayer_perceptron.html#nerva_torch.multilayer_perceptron.MultilayerPerceptron.optimize">(nerva_torch.multilayer_perceptron.MultilayerPerceptron method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.optimizers.html#nerva_torch.optimizers.Optimizer">Optimizer (class in nerva_torch.optimizers)</a>
</li>
      <li><a href="_autosummary/nerva_torch.layers.html#nerva_torch.layers.BatchNormalizationLayer.output_size">output_size() (nerva_torch.layers.BatchNormalizationLayer method)</a>

      <ul>
        <li><a href="_autosummary/nerva_torch.layers.html#nerva_torch.layers.LinearLayer.output_size">(nerva_torch.layers.LinearLayer method)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="P">P</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.activation_functions.html#nerva_torch.activation_functions.parse_activation">parse_activation() (in module nerva_torch.activation_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.utilities.html#nerva_torch.utilities.parse_function_call">parse_function_call() (in module nerva_torch.utilities)</a>
</li>
      <li><a href="_autosummary/nerva_torch.learning_rate.html#nerva_torch.learning_rate.parse_learning_rate">parse_learning_rate() (in module nerva_torch.learning_rate)</a>
</li>
      <li><a href="_autosummary/nerva_torch.layers.html#nerva_torch.layers.parse_linear_layer">parse_linear_layer() (in module nerva_torch.layers)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.parse_loss_function">parse_loss_function() (in module nerva_torch.loss_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.multilayer_perceptron.html#nerva_torch.multilayer_perceptron.parse_multilayer_perceptron">parse_multilayer_perceptron() (in module nerva_torch.multilayer_perceptron)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.optimizers.html#nerva_torch.optimizers.parse_optimizer">parse_optimizer() (in module nerva_torch.optimizers)</a>
</li>
      <li><a href="_autosummary/nerva_torch.utilities.html#nerva_torch.utilities.pp">pp() (in module nerva_torch.utilities)</a>
</li>
      <li><a href="_autosummary/nerva_torch.utilities.html#nerva_torch.utilities.pp_numpy">pp_numpy() (in module nerva_torch.utilities)</a>
</li>
      <li><a href="_autosummary/nerva_torch.training.html#nerva_torch.training.print_batch_debug_info">print_batch_debug_info() (in module nerva_torch.training)</a>
</li>
      <li><a href="_autosummary/nerva_torch.training.html#nerva_torch.training.print_epoch">print_epoch() (in module nerva_torch.training)</a>
</li>
      <li><a href="_autosummary/nerva_torch.matrix_operations.html#nerva_torch.matrix_operations.product">product() (in module nerva_torch.matrix_operations)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="R">R</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.matrix_operations.html#nerva_torch.matrix_operations.reciprocal">reciprocal() (in module nerva_torch.matrix_operations)</a>
</li>
      <li><a href="_autosummary/nerva_torch.activation_functions.html#nerva_torch.activation_functions.Relu">Relu() (in module nerva_torch.activation_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.activation_functions.html#nerva_torch.activation_functions.Relu_gradient">Relu_gradient() (in module nerva_torch.activation_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.activation_functions.html#nerva_torch.activation_functions.ReLUActivation">ReLUActivation (class in nerva_torch.activation_functions)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.utilities.html#nerva_torch.utilities.StopWatch.reset">reset() (nerva_torch.utilities.StopWatch method)</a>
</li>
      <li><a href="_autosummary/nerva_torch.matrix_operations.html#nerva_torch.matrix_operations.row_repeat">row_repeat() (in module nerva_torch.matrix_operations)</a>
</li>
      <li><a href="_autosummary/nerva_torch.matrix_operations.html#nerva_torch.matrix_operations.rows_max">rows_max() (in module nerva_torch.matrix_operations)</a>
</li>
      <li><a href="_autosummary/nerva_torch.matrix_operations.html#nerva_torch.matrix_operations.rows_mean">rows_mean() (in module nerva_torch.matrix_operations)</a>
</li>
      <li><a href="_autosummary/nerva_torch.matrix_operations.html#nerva_torch.matrix_operations.rows_sum">rows_sum() (in module nerva_torch.matrix_operations)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="S">S</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.utilities.html#nerva_torch.utilities.save_dict_to_npz">save_dict_to_npz() (in module nerva_torch.utilities)</a>
</li>
      <li><a href="_autosummary/nerva_torch.multilayer_perceptron.html#nerva_torch.multilayer_perceptron.MultilayerPerceptron.save_weights_and_bias">save_weights_and_bias() (nerva_torch.multilayer_perceptron.MultilayerPerceptron method)</a>
</li>
      <li><a href="_autosummary/nerva_torch.utilities.html#nerva_torch.utilities.StopWatch.seconds">seconds() (nerva_torch.utilities.StopWatch method)</a>
</li>
      <li><a href="_autosummary/nerva_torch.weight_initializers.html#nerva_torch.weight_initializers.set_bias_to_zero">set_bias_to_zero() (in module nerva_torch.weight_initializers)</a>
</li>
      <li><a href="_autosummary/nerva_torch.weight_initializers.html#nerva_torch.weight_initializers.set_layer_weights">set_layer_weights() (in module nerva_torch.weight_initializers)</a>
</li>
      <li><a href="_autosummary/nerva_torch.utilities.html#nerva_torch.utilities.set_numpy_options">set_numpy_options() (in module nerva_torch.utilities)</a>
</li>
      <li><a href="_autosummary/nerva_torch.layers.html#nerva_torch.layers.BatchNormalizationLayer.set_optimizer">set_optimizer() (nerva_torch.layers.BatchNormalizationLayer method)</a>

      <ul>
        <li><a href="_autosummary/nerva_torch.layers.html#nerva_torch.layers.LinearLayer.set_optimizer">(nerva_torch.layers.LinearLayer method)</a>
</li>
        <li><a href="_autosummary/nerva_torch.layers.html#nerva_torch.layers.SReLULayer.set_optimizer">(nerva_torch.layers.SReLULayer method)</a>
</li>
      </ul></li>
      <li><a href="_autosummary/nerva_torch.utilities.html#nerva_torch.utilities.set_torch_options">set_torch_options() (in module nerva_torch.utilities)</a>
</li>
      <li><a href="_autosummary/nerva_torch.layers.html#nerva_torch.layers.LinearLayer.set_weights">set_weights() (nerva_torch.layers.LinearLayer method)</a>
</li>
      <li><a href="_autosummary/nerva_torch.weight_initializers.html#nerva_torch.weight_initializers.set_weights_he">set_weights_he() (in module nerva_torch.weight_initializers)</a>
</li>
      <li><a href="_autosummary/nerva_torch.weight_initializers.html#nerva_torch.weight_initializers.set_weights_xavier">set_weights_xavier() (in module nerva_torch.weight_initializers)</a>
</li>
      <li><a href="_autosummary/nerva_torch.weight_initializers.html#nerva_torch.weight_initializers.set_weights_xavier_normalized">set_weights_xavier_normalized() (in module nerva_torch.weight_initializers)</a>
</li>
      <li><a href="_autosummary/nerva_torch.training.html#nerva_torch.training.SGDOptions">SGDOptions (class in nerva_torch.training)</a>
</li>
      <li><a href="_autosummary/nerva_torch.activation_functions.html#nerva_torch.activation_functions.Sigmoid">Sigmoid() (in module nerva_torch.activation_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.activation_functions.html#nerva_torch.activation_functions.Sigmoid_gradient">Sigmoid_gradient() (in module nerva_torch.activation_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.activation_functions.html#nerva_torch.activation_functions.SigmoidActivation">SigmoidActivation (class in nerva_torch.activation_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.softmax_functions.html#nerva_torch.softmax_functions.softmax">softmax() (in module nerva_torch.softmax_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.Softmax_cross_entropy_loss">Softmax_cross_entropy_loss() (in module nerva_torch.loss_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.softmax_cross_entropy_loss">softmax_cross_entropy_loss() (in module nerva_torch.loss_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.Softmax_cross_entropy_loss_gradient">Softmax_cross_entropy_loss_gradient() (in module nerva_torch.loss_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.softmax_cross_entropy_loss_gradient">softmax_cross_entropy_loss_gradient() (in module nerva_torch.loss_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.Softmax_cross_entropy_loss_gradient_one_hot">Softmax_cross_entropy_loss_gradient_one_hot() (in module nerva_torch.loss_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.softmax_cross_entropy_loss_gradient_one_hot">softmax_cross_entropy_loss_gradient_one_hot() (in module nerva_torch.loss_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions_torch.html#nerva_torch.loss_functions_torch.softmax_cross_entropy_loss_torch">softmax_cross_entropy_loss_torch() (in module nerva_torch.loss_functions_torch)</a>
</li>
      <li><a href="_autosummary/nerva_torch.softmax_functions.html#nerva_torch.softmax_functions.softmax_jacobian">softmax_jacobian() (in module nerva_torch.softmax_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.SoftmaxCrossEntropyLossFunction">SoftmaxCrossEntropyLossFunction (class in nerva_torch.loss_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.softmax_functions.html#nerva_torch.softmax_functions.SoftmaxFunction">SoftmaxFunction (class in nerva_torch.softmax_functions)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.layers.html#nerva_torch.layers.SoftmaxLayer">SoftmaxLayer (class in nerva_torch.layers)</a>
</li>
      <li><a href="_autosummary/nerva_torch.matrix_operations.html#nerva_torch.matrix_operations.sqrt">sqrt() (in module nerva_torch.matrix_operations)</a>
</li>
      <li><a href="_autosummary/nerva_torch.matrix_operations.html#nerva_torch.matrix_operations.square">square() (in module nerva_torch.matrix_operations)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.Squared_error_loss">Squared_error_loss() (in module nerva_torch.loss_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.squared_error_loss">squared_error_loss() (in module nerva_torch.loss_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.Squared_error_loss_gradient">Squared_error_loss_gradient() (in module nerva_torch.loss_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.squared_error_loss_gradient">squared_error_loss_gradient() (in module nerva_torch.loss_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions_torch.html#nerva_torch.loss_functions_torch.squared_error_loss_torch">squared_error_loss_torch() (in module nerva_torch.loss_functions_torch)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.SquaredErrorLossFunction">SquaredErrorLossFunction (class in nerva_torch.loss_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.activation_functions.html#nerva_torch.activation_functions.Srelu">Srelu() (in module nerva_torch.activation_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.activation_functions.html#nerva_torch.activation_functions.Srelu_gradient">Srelu_gradient() (in module nerva_torch.activation_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.activation_functions.html#nerva_torch.activation_functions.SReLUActivation">SReLUActivation (class in nerva_torch.activation_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.layers.html#nerva_torch.layers.SReLULayer">SReLULayer (class in nerva_torch.layers)</a>
</li>
      <li><a href="_autosummary/nerva_torch.softmax_functions.html#nerva_torch.softmax_functions.stable_log_softmax">stable_log_softmax() (in module nerva_torch.softmax_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.softmax_functions.html#nerva_torch.softmax_functions.stable_log_softmax_jacobian">stable_log_softmax_jacobian() (in module nerva_torch.softmax_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.softmax_functions.html#nerva_torch.softmax_functions.stable_softmax">stable_softmax() (in module nerva_torch.softmax_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.Stable_softmax_cross_entropy_loss">Stable_softmax_cross_entropy_loss() (in module nerva_torch.loss_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.stable_softmax_cross_entropy_loss">stable_softmax_cross_entropy_loss() (in module nerva_torch.loss_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.Stable_softmax_cross_entropy_loss_gradient">Stable_softmax_cross_entropy_loss_gradient() (in module nerva_torch.loss_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.stable_softmax_cross_entropy_loss_gradient">stable_softmax_cross_entropy_loss_gradient() (in module nerva_torch.loss_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.Stable_softmax_cross_entropy_loss_gradient_one_hot">Stable_softmax_cross_entropy_loss_gradient_one_hot() (in module nerva_torch.loss_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.stable_softmax_cross_entropy_loss_gradient_one_hot">stable_softmax_cross_entropy_loss_gradient_one_hot() (in module nerva_torch.loss_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.softmax_functions.html#nerva_torch.softmax_functions.stable_softmax_jacobian">stable_softmax_jacobian() (in module nerva_torch.softmax_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.softmax_functions.html#nerva_torch.softmax_functions.StableLogSoftmaxFunction">StableLogSoftmaxFunction (class in nerva_torch.softmax_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.loss_functions.html#nerva_torch.loss_functions.StableSoftmaxCrossEntropyLossFunction">StableSoftmaxCrossEntropyLossFunction (class in nerva_torch.loss_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.softmax_functions.html#nerva_torch.softmax_functions.StableSoftmaxFunction">StableSoftmaxFunction (class in nerva_torch.softmax_functions)</a>
</li>
      <li><a href="_autosummary/nerva_torch.learning_rate.html#nerva_torch.learning_rate.StepBasedScheduler">StepBasedScheduler (class in nerva_torch.learning_rate)</a>
</li>
      <li><a href="_autosummary/nerva_torch.training.html#nerva_torch.training.stochastic_gradient_descent">stochastic_gradient_descent() (in module nerva_torch.training)</a>
</li>
      <li><a href="_autosummary/nerva_torch.training.html#nerva_torch.training.stochastic_gradient_descent_plain">stochastic_gradient_descent_plain() (in module nerva_torch.training)</a>
</li>
      <li><a href="_autosummary/nerva_torch.utilities.html#nerva_torch.utilities.StopWatch">StopWatch (class in nerva_torch.utilities)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="T">T</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.learning_rate.html#nerva_torch.learning_rate.TimeBasedScheduler">TimeBasedScheduler (class in nerva_torch.learning_rate)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.datasets.html#nerva_torch.datasets.to_one_hot">to_one_hot() (in module nerva_torch.datasets)</a>
</li>
      <li><a href="_autosummary/nerva_torch.training.html#nerva_torch.training.train">train() (in module nerva_torch.training)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="U">U</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.optimizers.html#nerva_torch.optimizers.CompositeOptimizer.update">update() (nerva_torch.optimizers.CompositeOptimizer method)</a>

      <ul>
        <li><a href="_autosummary/nerva_torch.optimizers.html#nerva_torch.optimizers.GradientDescentOptimizer.update">(nerva_torch.optimizers.GradientDescentOptimizer method)</a>
</li>
        <li><a href="_autosummary/nerva_torch.optimizers.html#nerva_torch.optimizers.MomentumOptimizer.update">(nerva_torch.optimizers.MomentumOptimizer method)</a>
</li>
        <li><a href="_autosummary/nerva_torch.optimizers.html#nerva_torch.optimizers.NesterovOptimizer.update">(nerva_torch.optimizers.NesterovOptimizer method)</a>
</li>
        <li><a href="_autosummary/nerva_torch.optimizers.html#nerva_torch.optimizers.Optimizer.update">(nerva_torch.optimizers.Optimizer method)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="V">V</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.matrix_operations.html#nerva_torch.matrix_operations.vector_size">vector_size() (in module nerva_torch.matrix_operations)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="Z">Z</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="_autosummary/nerva_torch.matrix_operations.html#nerva_torch.matrix_operations.zeros">zeros() (in module nerva_torch.matrix_operations)</a>
</li>
  </ul></td>
</tr></table>



           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Wieger Wesselink and contributors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>
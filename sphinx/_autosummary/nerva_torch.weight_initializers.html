

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>nerva_torch.weight_initializers &mdash; nerva_torch  documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="nerva_torch.utilities" href="nerva_torch.utilities.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            nerva_torch
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="nerva_torch.html">nerva_torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="nerva_torch.activation_functions.html">nerva_torch.activation_functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="nerva_torch.datasets.html">nerva_torch.datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="nerva_torch.layers.html">nerva_torch.layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="nerva_torch.learning_rate.html">nerva_torch.learning_rate</a></li>
<li class="toctree-l1"><a class="reference internal" href="nerva_torch.loss_functions.html">nerva_torch.loss_functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="nerva_torch.loss_functions_torch.html">nerva_torch.loss_functions_torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="nerva_torch.matrix_operations.html">nerva_torch.matrix_operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="nerva_torch.multilayer_perceptron.html">nerva_torch.multilayer_perceptron</a></li>
<li class="toctree-l1"><a class="reference internal" href="nerva_torch.optimizers.html">nerva_torch.optimizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="nerva_torch.softmax_functions.html">nerva_torch.softmax_functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="nerva_torch.training.html">nerva_torch.training</a></li>
<li class="toctree-l1"><a class="reference internal" href="nerva_torch.utilities.html">nerva_torch.utilities</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">nerva_torch.weight_initializers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#nerva_torch.weight_initializers.set_bias_zero"><code class="docutils literal notranslate"><span class="pre">set_bias_zero()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#nerva_torch.weight_initializers.set_bias_uniform"><code class="docutils literal notranslate"><span class="pre">set_bias_uniform()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#nerva_torch.weight_initializers.set_bias_normal"><code class="docutils literal notranslate"><span class="pre">set_bias_normal()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#nerva_torch.weight_initializers.set_weights_uniform"><code class="docutils literal notranslate"><span class="pre">set_weights_uniform()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#nerva_torch.weight_initializers.set_weights_normal"><code class="docutils literal notranslate"><span class="pre">set_weights_normal()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#nerva_torch.weight_initializers.set_weights_xavier_uniform"><code class="docutils literal notranslate"><span class="pre">set_weights_xavier_uniform()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#nerva_torch.weight_initializers.set_weights_xavier_normal"><code class="docutils literal notranslate"><span class="pre">set_weights_xavier_normal()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#nerva_torch.weight_initializers.set_weights_he_normal"><code class="docutils literal notranslate"><span class="pre">set_weights_he_normal()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#nerva_torch.weight_initializers.set_weights_he_uniform"><code class="docutils literal notranslate"><span class="pre">set_weights_he_uniform()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#nerva_torch.weight_initializers.set_weights_zero"><code class="docutils literal notranslate"><span class="pre">set_weights_zero()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#nerva_torch.weight_initializers.set_layer_weights"><code class="docutils literal notranslate"><span class="pre">set_layer_weights()</span></code></a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">nerva_torch</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="nerva_torch.html">nerva_torch</a></li>
      <li class="breadcrumb-item active">nerva_torch.weight_initializers</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/_autosummary/nerva_torch.weight_initializers.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-nerva_torch.weight_initializers">
<span id="nerva-torch-weight-initializers"></span><h1>nerva_torch.weight_initializers<a class="headerlink" href="#module-nerva_torch.weight_initializers" title="Link to this heading"></a></h1>
<p>Weight and bias initialization helpers for linear layers.</p>
<p class="rubric">Functions</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#nerva_torch.weight_initializers.set_bias_normal" title="nerva_torch.weight_initializers.set_bias_normal"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_bias_normal</span></code></a>(b[, mean, std])</p></td>
<td><p>Normal (Gaussian) initialization with given mean and std.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nerva_torch.weight_initializers.set_bias_uniform" title="nerva_torch.weight_initializers.set_bias_uniform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_bias_uniform</span></code></a>(b_[, a, b])</p></td>
<td><p>Uniform initialization within [a, b).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nerva_torch.weight_initializers.set_bias_zero" title="nerva_torch.weight_initializers.set_bias_zero"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_bias_zero</span></code></a>(b)</p></td>
<td><p>Set all bias values to zero.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nerva_torch.weight_initializers.set_layer_weights" title="nerva_torch.weight_initializers.set_layer_weights"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_layer_weights</span></code></a>(layer, text)</p></td>
<td><p>Initialize a layer's parameters according to a named scheme.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nerva_torch.weight_initializers.set_weights_he_normal" title="nerva_torch.weight_initializers.set_weights_he_normal"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_weights_he_normal</span></code></a>(W)</p></td>
<td><p>He / Kaiming normal initialization (for ReLU).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nerva_torch.weight_initializers.set_weights_he_uniform" title="nerva_torch.weight_initializers.set_weights_he_uniform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_weights_he_uniform</span></code></a>(W)</p></td>
<td><p>He / Kaiming uniform initialization (for ReLU, less common).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nerva_torch.weight_initializers.set_weights_normal" title="nerva_torch.weight_initializers.set_weights_normal"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_weights_normal</span></code></a>(W[, mean, std])</p></td>
<td><p>Normal (Gaussian) initialization with given mean and std.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nerva_torch.weight_initializers.set_weights_uniform" title="nerva_torch.weight_initializers.set_weights_uniform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_weights_uniform</span></code></a>(W[, a, b])</p></td>
<td><p>Uniform initialization within [a, b).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nerva_torch.weight_initializers.set_weights_xavier_normal" title="nerva_torch.weight_initializers.set_weights_xavier_normal"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_weights_xavier_normal</span></code></a>(W)</p></td>
<td><p>Xavier / Glorot normal initialization (for tanh/sigmoid).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nerva_torch.weight_initializers.set_weights_xavier_uniform" title="nerva_torch.weight_initializers.set_weights_xavier_uniform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_weights_xavier_uniform</span></code></a>(W)</p></td>
<td><p>Xavier / Glorot uniform initialization (for tanh/sigmoid).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nerva_torch.weight_initializers.set_weights_zero" title="nerva_torch.weight_initializers.set_weights_zero"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_weights_zero</span></code></a>(W)</p></td>
<td><p>Initialize weights to zero.</p></td>
</tr>
</tbody>
</table>
<dl class="py function">
<dt class="sig sig-object py" id="nerva_torch.weight_initializers.set_bias_zero">
<span class="sig-prename descclassname"><span class="pre">nerva_torch.weight_initializers.</span></span><span class="sig-name descname"><span class="pre">set_bias_zero</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">b</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nerva_torch/weight_initializers.html#set_bias_zero"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nerva_torch.weight_initializers.set_bias_zero" title="Link to this definition"></a></dt>
<dd><p>Set all bias values to zero.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nerva_torch.weight_initializers.set_bias_uniform">
<span class="sig-prename descclassname"><span class="pre">nerva_torch.weight_initializers.</span></span><span class="sig-name descname"><span class="pre">set_bias_uniform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">b_</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">a</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nerva_torch/weight_initializers.html#set_bias_uniform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nerva_torch.weight_initializers.set_bias_uniform" title="Link to this definition"></a></dt>
<dd><p>Uniform initialization within [a, b).</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nerva_torch.weight_initializers.set_bias_normal">
<span class="sig-prename descclassname"><span class="pre">nerva_torch.weight_initializers.</span></span><span class="sig-name descname"><span class="pre">set_bias_normal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">b</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nerva_torch/weight_initializers.html#set_bias_normal"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nerva_torch.weight_initializers.set_bias_normal" title="Link to this definition"></a></dt>
<dd><p>Normal (Gaussian) initialization with given mean and std.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nerva_torch.weight_initializers.set_weights_uniform">
<span class="sig-prename descclassname"><span class="pre">nerva_torch.weight_initializers.</span></span><span class="sig-name descname"><span class="pre">set_weights_uniform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">W</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">a</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nerva_torch/weight_initializers.html#set_weights_uniform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nerva_torch.weight_initializers.set_weights_uniform" title="Link to this definition"></a></dt>
<dd><p>Uniform initialization within [a, b).</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nerva_torch.weight_initializers.set_weights_normal">
<span class="sig-prename descclassname"><span class="pre">nerva_torch.weight_initializers.</span></span><span class="sig-name descname"><span class="pre">set_weights_normal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">W</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nerva_torch/weight_initializers.html#set_weights_normal"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nerva_torch.weight_initializers.set_weights_normal" title="Link to this definition"></a></dt>
<dd><p>Normal (Gaussian) initialization with given mean and std.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nerva_torch.weight_initializers.set_weights_xavier_uniform">
<span class="sig-prename descclassname"><span class="pre">nerva_torch.weight_initializers.</span></span><span class="sig-name descname"><span class="pre">set_weights_xavier_uniform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">W</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nerva_torch/weight_initializers.html#set_weights_xavier_uniform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nerva_torch.weight_initializers.set_weights_xavier_uniform" title="Link to this definition"></a></dt>
<dd><p>Xavier / Glorot uniform initialization (for tanh/sigmoid).</p>
<p>K = fan-out (output size)
D = fan-in  (input size)</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nerva_torch.weight_initializers.set_weights_xavier_normal">
<span class="sig-prename descclassname"><span class="pre">nerva_torch.weight_initializers.</span></span><span class="sig-name descname"><span class="pre">set_weights_xavier_normal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">W</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nerva_torch/weight_initializers.html#set_weights_xavier_normal"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nerva_torch.weight_initializers.set_weights_xavier_normal" title="Link to this definition"></a></dt>
<dd><p>Xavier / Glorot normal initialization (for tanh/sigmoid).</p>
<p>K = fan-out (output size)
D = fan-in  (input size)</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nerva_torch.weight_initializers.set_weights_he_normal">
<span class="sig-prename descclassname"><span class="pre">nerva_torch.weight_initializers.</span></span><span class="sig-name descname"><span class="pre">set_weights_he_normal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">W</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nerva_torch/weight_initializers.html#set_weights_he_normal"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nerva_torch.weight_initializers.set_weights_he_normal" title="Link to this definition"></a></dt>
<dd><p>He / Kaiming normal initialization (for ReLU).</p>
<p>K = fan-out (output size)
D = fan-in  (input size)</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nerva_torch.weight_initializers.set_weights_he_uniform">
<span class="sig-prename descclassname"><span class="pre">nerva_torch.weight_initializers.</span></span><span class="sig-name descname"><span class="pre">set_weights_he_uniform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">W</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nerva_torch/weight_initializers.html#set_weights_he_uniform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nerva_torch.weight_initializers.set_weights_he_uniform" title="Link to this definition"></a></dt>
<dd><p>He / Kaiming uniform initialization (for ReLU, less common).</p>
<p>K = fan-out (output size)
D = fan-in  (input size)</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nerva_torch.weight_initializers.set_weights_zero">
<span class="sig-prename descclassname"><span class="pre">nerva_torch.weight_initializers.</span></span><span class="sig-name descname"><span class="pre">set_weights_zero</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">W</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nerva_torch/weight_initializers.html#set_weights_zero"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nerva_torch.weight_initializers.set_weights_zero" title="Link to this definition"></a></dt>
<dd><p>Initialize weights to zero.</p>
<p>Note: Initializing all weights to zero is generally not recommended because
it causes all neurons to learn the same features during training, leading to
symmetry that prevents effective learning and updates (the “symmetry breaking” problem).
This initializer can be useful for biases or special cases but should be avoided for weights.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nerva_torch.weight_initializers.set_layer_weights">
<span class="sig-prename descclassname"><span class="pre">nerva_torch.weight_initializers.</span></span><span class="sig-name descname"><span class="pre">set_layer_weights</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nerva_torch/weight_initializers.html#set_layer_weights"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nerva_torch.weight_initializers.set_layer_weights" title="Link to this definition"></a></dt>
<dd><p>Initialize a layer’s parameters according to a named scheme.</p>
</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="nerva_torch.utilities.html" class="btn btn-neutral float-left" title="nerva_torch.utilities" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Wieger Wesselink and contributors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>